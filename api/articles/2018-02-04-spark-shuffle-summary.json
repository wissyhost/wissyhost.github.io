{"title":"Spark  Shuffle总结","slug":"2018-02-04-spark-shuffle-summary","date":"2018-02-04T05:42:59.000Z","updated":"2019-12-08T16:56:55.000Z","comments":false,"path":"api/articles/2018-02-04-spark-shuffle-summary.json","excerpt":"Spark  Shuffle的过程：1.1 以前 Hash Shuffle<br>1.1.x 添加Sort Shuffle<br>1.5.x 添加Unsafe Shuffle<br>1.6.x 合并Unsafe Shuffle和Sort Shuffle<br>2.0.x 移除Hash Shuffle","covers":null,"content":"<link rel=\"stylesheet\" href=\"/assets/css/hint.min.css\"></link><link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css\"><link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/lightgallery.js/1.0.1/css/lightgallery.min.css\"><div class=\".article-gallery\" <h2 id=\"Spark-Shuffle的过程：\"><a href=\"#Spark-Shuffle的过程：\" class=\"headerlink\" title=\"Spark  Shuffle的过程：\"></a>Spark  Shuffle的过程：<p>1.1 以前 Hash Shuffle<br>1.1.x 添加Sort Shuffle<br>1.5.x 添加Unsafe Shuffle<br>1.6.x 合并Unsafe Shuffle和Sort Shuffle<br>2.0.x 移除Hash Shuffle</p>\n<a id=\"more\"></a>\n\n<h4 id=\"Hash-Shuffle-v1：\"><a href=\"#Hash-Shuffle-v1：\" class=\"headerlink\" title=\"Hash Shuffle v1：\"></a>Hash Shuffle v1：</h4><p>每个map会为下游stage的partition写一个文件，如果有1000个分区的话会生成m×1000个临时文件，一般来说excutor都会运行多个task，另一方面一个excutor都有K个Core，那么会申请KN个文件描述符，一旦partition较多，必定会耗尽，同事也会带来 内存消耗</p>\n<p>在reduce阶段会拉取上游产生的数据，所有的文件都需要网络来传输，又涉及到大量的文件描述符，如果reduce段有combiner的操作，需要将网络上的数据保存到HashMap中进行合并，数据量大必定会OOM</p>\n<h4 id=\"Hash-Shuffle-v2：\"><a href=\"#Hash-Shuffle-v2：\" class=\"headerlink\" title=\"Hash Shuffle v2：\"></a>Hash Shuffle v2：</h4><p>在上面生成分区文件的过程中每个excutor只生成n个partition文件，对其他task生成partition进行和并，在reduce端读取分区文件的过程中，势必会造成OOM</p>\n<h4 id=\"Sort-Shuffle-v1：\"><a href=\"#Sort-Shuffle-v1：\" class=\"headerlink\" title=\"Sort Shuffle v1：\"></a>Sort Shuffle v1：</h4><p>受Hadoop MapReduce Shuffle的影响，引入Sort Shuffle</p>\n<p>在map端会按照partition id和key进行排序，将所有分区的数据写在同一个文件中，该记录首先会按照分区id顺序排序，每个分区内部按照key进行排序，map task期间会顺序写每个分区的数据，并通过索引数据记录每个分区的大小个偏移量，一个map task只开两个文件描述符，即使有K个core，也只有k×2个文件描述符</p>\n<p>在Reduce阶段，做reduce combiner时使用ExternalAppendOnlyMap，在大数据量的情况下，做combiner时如果内存不够，会刷写磁盘，避免了OOM</p>\n<p>解决了Hash Shuffle的弊端，但是在Shuffle过程中要对数据进行排序，所以性能有所损失</p>\n<h4 id=\"Unsafe-Shuffle：\"><a href=\"#Unsafe-Shuffle：\" class=\"headerlink\" title=\"Unsafe Shuffle：\"></a>Unsafe Shuffle：</h4><p>钨丝计划重在解决内存和CPU的使用，刚开始是在优化Spark SQL，Shuffle也因此受益，做法是直接在序列化的二进制数据上面进行排序，减少了内存的使用和GC，在排序中使用cache-efficient sorter，使用8byte的指针，把排序转化为指针数组的排序</p>\n<p>但是使用Unsafe Shuffle有几个限制，shuffle阶段不能有aggregate操作，分区数不能超过一定大小(224−1，这是可编码的最大parition id)，所以像reduceByKey这类有aggregate操作的算子是不能使用Unsafe Shuffle，它会退化采用Sort Shuffle。</p>\n<h4 id=\"Sort-Shuffle-v2：\"><a href=\"#Sort-Shuffle-v2：\" class=\"headerlink\" title=\"Sort Shuffle v2：\"></a>Sort Shuffle v2：</h4><p>在满足Unsafe Shuffle 的情况下自动使用，否则使用Sort Shuffle，从spark 2.0后移除了Hash Shuffle 也就是只有Sort Shuffle v2</p>\n</div><script src=\"https://cdn.jsdelivr.net/lightgallery.js/1.0.1/js/lightgallery.min.js\"></script><script>if (typeof lightGallery !== 'undefined') {\n        var options = {\n            selector: '.gallery-item'\n        };\n        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);\n        }</script>","more":"<h4 id=\"Hash-Shuffle-v1：\"><a href=\"#Hash-Shuffle-v1：\" class=\"headerlink\" title=\"Hash Shuffle v1：\"></a>Hash Shuffle v1：</h4><p>每个map会为下游stage的partition写一个文件，如果有1000个分区的话会生成m×1000个临时文件，一般来说excutor都会运行多个task，另一方面一个excutor都有K个Core，那么会申请KN个文件描述符，一旦partition较多，必定会耗尽，同事也会带来 内存消耗</p>\n<p>在reduce阶段会拉取上游产生的数据，所有的文件都需要网络来传输，又涉及到大量的文件描述符，如果reduce段有combiner的操作，需要将网络上的数据保存到HashMap中进行合并，数据量大必定会OOM</p>\n<h4 id=\"Hash-Shuffle-v2：\"><a href=\"#Hash-Shuffle-v2：\" class=\"headerlink\" title=\"Hash Shuffle v2：\"></a>Hash Shuffle v2：</h4><p>在上面生成分区文件的过程中每个excutor只生成n个partition文件，对其他task生成partition进行和并，在reduce端读取分区文件的过程中，势必会造成OOM</p>\n<h4 id=\"Sort-Shuffle-v1：\"><a href=\"#Sort-Shuffle-v1：\" class=\"headerlink\" title=\"Sort Shuffle v1：\"></a>Sort Shuffle v1：</h4><p>受Hadoop MapReduce Shuffle的影响，引入Sort Shuffle</p>\n<p>在map端会按照partition id和key进行排序，将所有分区的数据写在同一个文件中，该记录首先会按照分区id顺序排序，每个分区内部按照key进行排序，map task期间会顺序写每个分区的数据，并通过索引数据记录每个分区的大小个偏移量，一个map task只开两个文件描述符，即使有K个core，也只有k×2个文件描述符</p>\n<p>在Reduce阶段，做reduce combiner时使用ExternalAppendOnlyMap，在大数据量的情况下，做combiner时如果内存不够，会刷写磁盘，避免了OOM</p>\n<p>解决了Hash Shuffle的弊端，但是在Shuffle过程中要对数据进行排序，所以性能有所损失</p>\n<h4 id=\"Unsafe-Shuffle：\"><a href=\"#Unsafe-Shuffle：\" class=\"headerlink\" title=\"Unsafe Shuffle：\"></a>Unsafe Shuffle：</h4><p>钨丝计划重在解决内存和CPU的使用，刚开始是在优化Spark SQL，Shuffle也因此受益，做法是直接在序列化的二进制数据上面进行排序，减少了内存的使用和GC，在排序中使用cache-efficient sorter，使用8byte的指针，把排序转化为指针数组的排序</p>\n<p>但是使用Unsafe Shuffle有几个限制，shuffle阶段不能有aggregate操作，分区数不能超过一定大小(224−1，这是可编码的最大parition id)，所以像reduceByKey这类有aggregate操作的算子是不能使用Unsafe Shuffle，它会退化采用Sort Shuffle。</p>\n<h4 id=\"Sort-Shuffle-v2：\"><a href=\"#Sort-Shuffle-v2：\" class=\"headerlink\" title=\"Sort Shuffle v2：\"></a>Sort Shuffle v2：</h4><p>在满足Unsafe Shuffle 的情况下自动使用，否则使用Sort Shuffle，从spark 2.0后移除了Hash Shuffle 也就是只有Sort Shuffle v2</p>\n</div><script src=\"https://cdn.jsdelivr.net/lightgallery.js/1.0.1/js/lightgallery.min.js\"></script><script>if (typeof lightGallery !== 'undefined') {\n        var options = {\n            selector: '.gallery-item'\n        };\n        lightGallery(document.getElementsByClassName('.article-gallery')[0], options);\n        }</script>","categories":[{"name":"Spark","path":"api/categories/Spark.json"}],"tags":[{"name":"spark","path":"api/tags/spark.json"},{"name":"shuffle","path":"api/tags/shuffle.json"},{"name":"Hash Shuffle","path":"api/tags/Hash Shuffle.json"},{"name":"Sort Shuffle","path":"api/tags/Sort Shuffle.json"}]}